# kag_titanic
We discuss and evaluate multiple concepts and models here
1. Logistic regression
2. Random forest Classification
3. SVM classification
4. XGBoost
5. Imputation for missing data - Using regression to fill missing data
6. Feature Engineering

And with some inputs from another submission (referred to in the notebook) we achieve 77.99% accuracy 

On the leadership board there are submissions with higher accuracy, but I looked at one such solution and for higher solutions people seem to be handcrafting models of their own instead of using standard models. It may be good analysis. But if you want to look at different models and evaluation techniques then you can refer to my solution here.
