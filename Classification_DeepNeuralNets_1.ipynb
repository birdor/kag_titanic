{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic\n",
    "\n",
    "Deep Neural Networks - Version 1\n",
    "\n",
    "Only \n",
    "1. He_Initialization & \n",
    "2. Nesterov Optimization\n",
    "\n",
    "No Batch Optimization and Drop out regularization\n",
    "\n",
    "Overfits the training data. Provides a dismal 70.8% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore warnings \n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the Training data\n",
    "#### Step1 - Change the categorical variables to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:6576: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# Lets use Pclass, Sex, Age, SibSp, Parch, Fare, Embarked\n",
    "\n",
    "train_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].isnull().any()\n",
    "#Lets predict the age from the Fare, Sex, Pclass, parch and SubSp and use it\n",
    "\n",
    "selected_df = train_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'PassengerId', 'Survived']]\n",
    "\n",
    "#Sex\n",
    "selected_df['Sex'].replace('male',0, inplace=True)\n",
    "selected_df['Sex'].replace('female',1, inplace=True)\n",
    "\n",
    "#Embarked\n",
    "selected_df['Embarked'].replace('S', 0, inplace=True)\n",
    "selected_df['Embarked'].replace('C', 1, inplace=True)\n",
    "selected_df['Embarked'].replace('Q', 2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute for Predictors with missing values \n",
    "#### Step 2 - Use regression to predict the age missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3267: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Select sepcific rows\n",
    "age_select = selected_df.loc[selected_df['Age'].notnull(),['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "\n",
    "# Regression\n",
    "lmod_age = lm.LinearRegression()\n",
    "lmod_age.fit(age_select[['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare']], age_select['Age'])\n",
    "\n",
    "selected_df['predicted_age'] = lmod_age.predict(selected_df[['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare']])\n",
    "\n",
    "# Fill back the age correctly\n",
    "#selected_df[['Age', 'predicted_age']].Age\n",
    "#selected_df[['Age','predicted_age']].apply(lambda x: x)\n",
    "\n",
    "age = selected_df['Age']\n",
    "pred_age = selected_df['predicted_age']\n",
    "\n",
    "#selected_df['Age'] = np.where(math.isnan(age) is True, pred_age, age)\n",
    "\n",
    "for ind, row in selected_df.iterrows():\n",
    "    if math.isnan(row['Age']) is True:\n",
    "        if(row['predicted_age'] > 0 ):\n",
    "            selected_df['Age'][ind] = row['predicted_age']\n",
    "        else:\n",
    "            selected_df['Age'][ind] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct test data\n",
    "#### 1. Handle categorical predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    False\n",
       "Sex       False\n",
       "SibSp     False\n",
       "Parch     False\n",
       "Fare       True\n",
       "Age        True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Sex'].replace('male',0, inplace=True)\n",
    "test_df['Sex'].replace('female',1, inplace=True)\n",
    "\n",
    "test_df[['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Age']].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# There is only one value missing in Fare and we adjust that as per ticket prices as per observation\n",
    "for ind, row in test_df.iterrows():\n",
    "    if math.isnan(row['Fare']) is True:\n",
    "        test_df['Fare'][ind] = 7.8958\n",
    "\n",
    "# Setting the age\n",
    "test_df['predicted_age'] = lmod_age.predict(test_df[['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare']])\n",
    "\n",
    "# Correct Age\n",
    "for ind, row in test_df.iterrows():\n",
    "    if math.isnan(row['Age']) is True:\n",
    "        if(row['predicted_age'] > 0 ):\n",
    "            test_df['Age'][ind] = row['predicted_age']\n",
    "        else:\n",
    "            test_df['Age'][ind] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = selected_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "y_train = selected_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering\n",
    "[Name based Feature Engineering](https://www.kaggle.com/cdeotte/titanic-using-name-only-0-81818)\n",
    "\n",
    "Refer to that article to understand how someone created a new feature based on family name groupings. We use that information to build a new XGBoost model and see if it bumps up our score. It is not worth spending more time than this. So, I will just attempt this one feature engineering attempt here.\n",
    "\n",
    "What these guys are doing is this\n",
    "* If a surname-woman-child combination is found to be alive in training set then they are borrowing that same surname-woman-child combination information to the test set\n",
    "* By default they are assuming that all women have survived. Which means they have only corrected for those cases where they definitely know the outcome from training set\n",
    "\n",
    "This looks a bit like gaming rather than modeling. But let us see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x_train['Name'] = train_df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "p = re.compile('.*, (.*?)\\.')\n",
    "x_train['Title'] = x_train['Name'].apply(lambda x: p.match(x).group(1))\n",
    "\n",
    "# Change the title now to either man / woman\n",
    "x_train['Title'] = x_train['Title'].apply(lambda x: -1 if x in [\"Capt\",\"Don\",\"Major\",\"Col\",\"Rev\",\"Dr\",\"Sir\",\"Mr\", \"Jonkheer\"] \n",
    "                                          else 1 if x in [\"Dona\",\"the Countess\",\"Mme\",\"Mlle\",\"Ms\",\"Miss\",\"Lady\",\"Mrs\"]\n",
    "                                                 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:8672: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3267: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Engineer \"woman-child-groups\"\n",
    "p = re.compile('(.*?),.*')\n",
    "x_train['Surname'] = x_train['Name'].apply(lambda x: p.match(x).group(1))\n",
    "\n",
    "# Bucket people into three groups. All males go into no-group (-1)\n",
    "x_train.Surname[x_train.Title==-1] = -1\n",
    "\n",
    "# Check the bucket sizes for others\n",
    "surnamefreq = x_train.groupby(['Surname']).size()\n",
    "x_train['SurnameFreq'] = x_train['Surname'].apply(lambda x: surnamefreq[x])\n",
    "\n",
    "# If the family group size is just one then call that as no-group (-1)\n",
    "x_train['Surname'][x_train['SurnameFreq'] <= 1] = -1\n",
    "\n",
    "# Update frequencies one final time\n",
    "surnamefreq = x_train.groupby(['Surname']).size()\n",
    "x_train['SurnameFreq'] = x_train['Surname'].apply(lambda x: surnamefreq[x])\n",
    "\n",
    "# Now all the remaining women and children group has to be marked as a single group because mother and child fates\n",
    "# identified to be intertwined (in that shared link)\n",
    "\n",
    "# Now change Surnames and Titles into numeric data to have them be handled by XGBoost\n",
    "#x_train['Surname'][x_train['Surname'] != -1] = 1\n",
    "#x_train['SurnameClass'] = x_train['Surname'].apply(lambda x: int(x))\n",
    "\n",
    "# Now write the survival rate for the women-child-family name combinations\n",
    "x_train['Survived'] = y_train\n",
    "name_survival = x_train.groupby(['Surname','Survived']).size()\n",
    "\n",
    "for ind, row in x_train.iterrows():\n",
    "    surived_c = 0\n",
    "    not_survived_c = 0\n",
    "    \n",
    "    if((row['Surname'],1) in name_survival.index):\n",
    "        survived_c = name_survival[row['Surname'],1]\n",
    "    else:\n",
    "        survived_c = 0\n",
    "    \n",
    "    if((row['Surname'],0) in name_survival.index):\n",
    "        not_survived_c = name_survival[row['Surname'],0]\n",
    "    else:\n",
    "        not_survived_c = 0\n",
    "        \n",
    "    if(survived_c + not_survived_c > 0):\n",
    "        x_train.loc[ind,'SurnameSurvival'] = survived_c/(survived_c + not_survived_c)\n",
    "    else:\n",
    "        x_train.loc[ind,'SurnameSurvival'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that there is a slight bump in the cross validated score to 86.08%. Let us see if it really works.\n",
    "##### Engineering the features for Test set now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "p = re.compile('.*, (.*?)\\.')\n",
    "test_df['Title'] = test_df['Name'].apply(lambda x: p.match(x).group(1))\n",
    "\n",
    "# Change the title now to either man / woman\n",
    "test_df['Title'] = test_df['Title'].apply(lambda x: -1 if x in [\"Capt\",\"Don\",\"Major\",\"Col\",\"Rev\",\"Dr\",\"Sir\",\"Mr\", \"Jonkheer\"] \n",
    "                                          else 1 if x in [\"Dona\",\"the Countess\",\"Mme\",\"Mlle\",\"Ms\",\"Miss\",\"Lady\",\"Mrs\"]\n",
    "                                                 else 0)\n",
    "\n",
    "# Engineer \"woman-child-groups\"\n",
    "p = re.compile('(.*?),.*')\n",
    "test_df['Surname'] = test_df['Name'].apply(lambda x: p.match(x).group(1))\n",
    "\n",
    "# Bucket people into three groups. All males go into no-group (-1)\n",
    "test_df.Surname[test_df.Title==-1] = -1\n",
    "\n",
    "# Check the bucket sizes for others\n",
    "surnamefreq = test_df.groupby(['Surname']).size()\n",
    "test_df['SurnameFreq'] = test_df['Surname'].apply(lambda x: surnamefreq[x])\n",
    "\n",
    "# If the family group size is just one then call that as no-group (-1)\n",
    "test_df['Surname'][test_df['SurnameFreq'] <= 1] = -1\n",
    "\n",
    "# Now all the remaining women and children group has to be marked as a single group because mother and child fates\n",
    "# identified to be intertwined (in that shared link)\n",
    "\n",
    "# Here borrow from training set\n",
    "test_df['SurnameSurvival'] = 0\n",
    "\n",
    "#test_df['Surname'].unique()\n",
    "\n",
    "for ind, row in test_df.iterrows():\n",
    "    if(row['Surname'] in x_train['Surname'].unique()):\n",
    "        test_df.loc[ind,'SurnameSurvival'] = x_train['SurnameSurvival'][x_train['Surname'] == row['Surname']].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler()\n",
    "data_train = scaler.fit_transform(x_train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'SurnameSurvival']])\n",
    "data_test = scaler.transform(test_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'SurnameSurvival']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a TensorFlow model\n",
    "\n",
    "We have 7 predictors and these we will blow out into 16 dimensions and then we will reduce it to half every time.\n",
    "\n",
    "11 X 7 > 7 X 16 > 16 X 8 > 8 X 4 > 4 X 1\n",
    "\n",
    "#### This has\n",
    "1. 1 Input layer\n",
    "2. 3 Hidden layers\n",
    "3. 1 Output layer\n",
    "\n",
    "#### And output is 0 / 1\n",
    "\n",
    "Design the initializers, variables and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neurons\n",
    "n_inputs = data_train.shape[1]\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 256\n",
    "n_hidden3 = 64\n",
    "n_outputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_inputs])\n",
    "y = tf.placeholder(dtype=tf.int64, shape=[None])\n",
    "\n",
    "# Performing drop_out to ensure that we do not overfit for the data.\n",
    "\n",
    "# He Initilization\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "# Using tensor flow neuron_layer function\n",
    "with tf.name_scope(\"dnn\"):\n",
    "\n",
    "    # This operation outputs False nothing is fed to it. So, it will return true only during the training phase\n",
    "    training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "    \n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "    \n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "    \n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, name=\"hidden3\", activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "    \n",
    "    logits = tf.layers.dense(hidden3, n_outputs, name=\"outputs\", kernel_initializer=he_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now start optimizing the cost function for the model\n",
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report the overall accuracy\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Train accuracy: 0.81930417\n",
      "1001 Train accuracy: 0.86195284\n",
      "2001 Train accuracy: 0.86756456\n",
      "3001 Train accuracy: 0.8731762\n",
      "4001 Train accuracy: 0.8810325\n",
      "5001 Train accuracy: 0.8821549\n",
      "6001 Train accuracy: 0.88439953\n",
      "7001 Train accuracy: 0.8855219\n",
      "8001 Train accuracy: 0.89001125\n",
      "9001 Train accuracy: 0.89001125\n"
     ]
    }
   ],
   "source": [
    "#Execution Phase\n",
    "n_epochs = 10010\n",
    "\n",
    "# Train on full batch\n",
    "\n",
    "# This is required to update operations related to batch_normalization at each step during the training in order to\n",
    "# update the moving averages\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run([training_op, extra_update_ops], feed_dict={training: True, X: data_train,y: y_train})\n",
    "        acc_train = accuracy.eval(feed_dict={X: data_train,y: y_train})        \n",
    "        \n",
    "        if(epoch%1000 == 1):\n",
    "            print(epoch, \"Train accuracy:\", acc_train)\n",
    "    \n",
    "    pred = logits.eval(feed_dict={X: data_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. How do I tune this model so that I do not overfit\n",
    "\n",
    "I am not trying to correct for overfitting here. I will just try with the overfit model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to compute the softmax scores here. Probably if I compute them, I can use them to check the PR-Curves etc.\n",
    "# But I will directly consume the data as it is with whichever logit is higher that is the class-number (0/1)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pred_df = pd.DataFrame(pred)\n",
    "pred_df.columns = ['zero','one']\n",
    "\n",
    "final = pred_df.apply(lambda x : 1 if x['zero'] < x['one'] else 0, axis = 1).astype(int)\n",
    "\n",
    "test_df['Survived'] = final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test and proceed\n",
    "\n",
    "Gives us a dismal 70.8% . Just shows why overfitting is a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResult = test_df[['PassengerId', 'Survived']]\n",
    "finalResult.to_csv(\"result_final_dnn_overfit.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
